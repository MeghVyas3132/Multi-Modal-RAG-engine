# ============================================================
# Multi-Modal RAG Engine — Environment Configuration
# Copy this to .env and adjust values for your environment.
# ============================================================

# ── CLIP Model ──────────────────────────────────────────────
CLIP_MODEL_NAME=ViT-H-14
CLIP_PRETRAINED=laion2b_s32b_b79k
# Dimension must match the model. ViT-H-14 = 1024, ViT-L-14 = 768, ViT-B-32 = 512
CLIP_VECTOR_DIM=1024
# Force CPU even if CUDA is available (set to "true" to disable GPU)
FORCE_CPU=false

# ── Qdrant ──────────────────────────────────────────────────
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_COLLECTION=image_vectors
# HNSW tuning — higher m = better recall, more RAM
QDRANT_HNSW_M=16
QDRANT_HNSW_EF_CONSTRUCT=200
# ef at search time — higher = better recall, higher latency
QDRANT_HNSW_EF=128

# ── Redis Cache ─────────────────────────────────────────────
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_CACHE_TTL=3600
REDIS_ENABLED=true

# ── API Server ──────────────────────────────────────────────
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1
# Keep workers=1 so the CLIP model is loaded once in RAM.
# Scale horizontally with multiple containers, not workers.

# ── Indexing ────────────────────────────────────────────────
IMAGE_DIR=./data/images
INDEX_BATCH_SIZE=256
INDEX_NUM_WORKERS=4

# ── LLM (optional) ─────────────────────────────────────────
LLM_ENABLED=false
LLM_MODEL=gpt-4
OPENAI_API_KEY=sk-...

# ── Search Defaults ─────────────────────────────────────────
SEARCH_TOP_K=10
SEARCH_SCORE_THRESHOLD=0.2
